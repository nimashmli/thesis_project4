from dataset.main import data , data_for_subject_dependet
import torch 
import os # os Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú†Ú© Ú©Ø±Ø¯Ù† cuda Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
from models_structures.hippoLegS1 import model
from train import Trainer
import random
from functions import k_fold_data_segmentation
from  torch.utils.data import DataLoader , TensorDataset
import numpy as np 
import torch.nn as nn
#____Model______#
def create_model(test_person , emotion,category , fold_idx, run_dir=None, config_path=None, config=None, resume=False) : 
    from pathlib import Path
    
    overlap = 0
    time_len = 1
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if category == 'binary'  :
        output_dim = 2 
    elif category == '5category' :
        output_dim = 5
    batch_size = 64
    data_type = torch.float32
    my_dataset = data(test_person, overlap, time_len, device, emotion, category, batch_size, data_type)
    train_loader = my_dataset.train_data()
    test_loader = my_dataset.test_data()

    x_dim , h_dim , seq_len ,c_dim = 14 , 24, 128*time_len, 64
    dim2 , dim3  = 64 , 16 
    Model = model( x_dim, h_dim, c_dim   ,seq_len,dim2 , dim3 , output_dim)# Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡
    # class weights for imbalance
    y_train = my_dataset.y_train
    class_count = torch.bincount(y_train.long())
    class_count = class_count + (class_count == 0).long()
    weights = (1.0 / class_count.float())
    weights = weights / weights.sum() * len(class_count)
    criterion = nn.CrossEntropyLoss(weight=weights.to(device))

    # ØªØ¹ÛŒÛŒÙ† Ù…Ø³ÛŒØ± checkpoint Ùˆ log
    if run_dir:
        run_dir = Path(run_dir)
        checkpoint_path = run_dir / f"checkpoint_fold{fold_idx}.pth"
        log_path = run_dir / f"log_fold{fold_idx}.json"
    else:
        checkpoint_path = f"eeg_checkpoint{fold_idx }.pth"
        log_path = f"eeg_log{fold_idx }.json"

    #____trainer_______#
    trainer = Trainer(
        model=Model,
        train_loader=train_loader,
        test_loader=test_loader,
        device=device,
        label_method=category,
        optimizer_cls=torch.optim.Adam,
        lr=5e-5,
        epochs=25,
        loss_fn = criterion ,
        checkpoint_path=str(checkpoint_path),
        log_path=str(log_path),
        config_path=config_path,
        save_each_epoch=True
    )
    #____fit_model_____#
    return  trainer.fit()

def subject_dependent_validation (emotion ,category, fold_idx , k=5, run_dir=None, config_path=None, config=None, resume=False) : 
    from pathlib import Path
    from experiment_manager import ExperimentManager
    
    overlap = 0
    time_len = 2
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if category == 'binary'  :
        output_dim = 2 
    elif category == '5category' :
        output_dim = 5
    batch_size = 64
    data_type = torch.float32
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ Ø§Ú¯Ø± resume=True Ø¨Ø§Ø´Ø¯
    accuracies_on_subjects = {
        'train' : [] , 
        'test' : []
    }
    start_subject = 0
    start_fold = 0
    current_subject = -1
    
    if resume and config and config_path:
        manager = ExperimentManager()
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† subject Ùˆ fold Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
        last_subject = config.get('last_completed_subject', -1)
        last_fold = config.get('last_completed_fold', -1)
        current_subject = config.get('current_subject', -1)
        
        # Ø§Ú¯Ø± subject Ù‚Ø¨Ù„ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡ØŒ Ø§Ø² subject Ø¨Ø¹Ø¯ÛŒ Ø´Ø±ÙˆØ¹ Ú©Ù†
        if last_fold == k - 1:  # Ù‡Ù…Ù‡ foldÙ‡Ø§ÛŒ subject Ù‚Ø¨Ù„ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡
            start_subject = last_subject + 1
            start_fold = 0
        else:  # subject Ù‚Ø¨Ù„ÛŒ Ù†ÛŒÙ…Ù‡â€ŒÚ©Ø§Ø±Ù‡ Ø§Ø³Øª
            start_subject = current_subject
            start_fold = last_fold + 1
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ
        if 'accuracies' in config:
            accuracies_on_subjects['train'] = config['accuracies'].get('train', [])
            accuracies_on_subjects['test'] = config['accuracies'].get('test', [])
        
        print(f"\nðŸ”„ Resuming from Subject {start_subject}, Fold {start_fold + 1} (previous subjects: {len(accuracies_on_subjects['train'])} completed)")
    
    person_num = start_subject
    data = data_for_subject_dependet(overlap , time_len ,emotion ,category ,data_type , device , k  )
    
    # ØªØ¨Ø¯ÛŒÙ„ iterator Ø¨Ù‡ Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ø§Ù…Ú©Ø§Ù† skip Ú©Ø±Ø¯Ù†
    data_list = list(data.data)
    
    # Ø´Ø±ÙˆØ¹ Ø§Ø² subject Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
    for subject_idx, (x , y) in enumerate(data_list[start_subject:], start=start_subject): 
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ current_subject Ø¯Ø± config
        if config_path and run_dir:
            manager = ExperimentManager()
            manager.update_experiment_config(
                config_path,
                current_subject=person_num
            )
        
        # Ø§Ú¯Ø± subject Ø¬Ø¯ÛŒØ¯ Ø§Ø³ØªØŒ Ø§Ø² fold 0 Ø´Ø±ÙˆØ¹ Ú©Ù†ØŒ ÙˆÚ¯Ø±Ù†Ù‡ Ø§Ø² fold Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
        if subject_idx == start_subject:
            fold_start = start_fold
        else:
            fold_start = 0
        
        fold_idx = fold_start
        len_data = x.shape[0]
        fold_number = len_data//k 
        all_x = [x[fold_number*i : min(fold_number*(i+1) , len_data) , : , : ] for i in range(k)]
        all_y = [y[fold_number*i : min(fold_number*(i+1) , len_data)] for i in range(k)]
        print("\n" + "="*60)
        print(f"Subject {person_num}: Training {k}-fold cross-validation")
        print("="*60)
        for i in range(fold_start, k): 
            print(f"\n-- Fold {i+1}/{k} --")
            x_test = all_x[i]
            y_test = all_y[i]
            x_train = all_x[:i] + all_x[i+1:]
            y_train = all_y[:i] + all_y[i+1:]
            x_train = torch.concat(x_train , dim=0)
            y_train = torch.concat(y_train , dim=0)

            test_dataset = TensorDataset(x_test , y_test)
            test_loader = DataLoader(test_dataset ,batch_size , shuffle=False)
            train_dataset = TensorDataset(x_train , y_train )
            train_loader = DataLoader(train_dataset , batch_size,shuffle=True )
            x_dim , h_dim , seq_len ,c_dim = 14 , 32 , 128*time_len, 32
            dim2 , dim3  = 64 , 16
            Model = model( x_dim, h_dim, c_dim   ,seq_len,dim2 , dim3 , output_dim)# Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡
            criterion = nn.CrossEntropyLoss()

            # ØªØ¹ÛŒÛŒÙ† Ù…Ø³ÛŒØ± checkpoint Ùˆ log
            if run_dir:
                run_dir = Path(run_dir)
                subject_dir = run_dir / f"subject_{person_num}"
                subject_dir.mkdir(exist_ok=True)
                checkpoint_path = subject_dir / f"checkpoint_fold{i}.pth"
                log_path = subject_dir / f"log_fold{i}.json"
            else:
                checkpoint_path = f"eeg_checkpoint{fold_idx + person_num*5}.pth"
                log_path = f"eeg_log{fold_idx + person_num*5}.json"

            #____trainer_______#
            # Ø¨Ø±Ø§ÛŒ subject_dependent Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ù†ÛŒØ³ØªØŒ Ø§Ù…Ø§ history Ø¨Ø§ÛŒØ¯ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯
            trainer = Trainer(
                model=Model,
                train_loader=train_loader,
                test_loader=test_loader,
                device=device,
                label_method=category,
                optimizer_cls=torch.optim.Adam,
                lr=5e-5,
                epochs=30,
                loss_fn = criterion ,
                verbose=True,
                save_each_epoch=True,  # Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ history Ø¯Ø± Ù‡Ø± epoch
                checkpoint_path=str(checkpoint_path),
                log_path=str(log_path),
                config_path=None  # Ø¨Ø±Ø§ÛŒ subject_dependent Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ config Ø¯Ø± trainer Ù†ÛŒØ³Øª
            )
            #____fit_model_____#
            history =  trainer.fit()
            
            # Ø°Ø®ÛŒØ±Ù‡ history Ø¯Ø± ÙØ§ÛŒÙ„ JSON (Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±)
            import json
            history_to_save = {
                'epoch': history['epoch'],
                'train_loss': [float(x) for x in history['train_loss']],
                'val_loss': [float(x) for x in history['val_loss']],
                'train_acc': [float(x) for x in history['train_acc']],
                'val_acc': [float(x) for x in history['val_acc']]
            }
            with open(log_path, 'w') as f:
                json.dump(history_to_save, f, indent=4)
            
            # Ø±Ø³Ù… Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† fold
            from plot import plot_training_history
            plot_training_history(history_to_save, save_dir=subject_dir, filename_prefix=f"fold_{i}")
            
            fold_train_acc = np.mean(np.array(history['train_acc'][-5:]))
            fold_val_acc = np.mean(np.array(history['val_acc'][-5:]))
            print(f"Fold {i+1} result -> Train Acc (last5 avg): {fold_train_acc:.2f}% | Test Acc (last5 avg): {fold_val_acc:.2f}%")
            if fold_idx ==0 : 
                train_loss = np.array(history['train_loss'])
                val_loss = np.array(history['val_loss'])
                train_acc = np.array(history['train_acc'])
                val_acc = np.array(history['val_acc'])
            else : 
                train_loss += np.array(history['train_loss'])
                val_loss += np.array(history['val_loss'])
                train_acc += np.array(history['train_acc'])
                val_acc += np.array(history['val_acc'])
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ config Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± fold
            if config_path and run_dir:
                manager = ExperimentManager()
                manager.update_experiment_config(
                    config_path,
                    last_completed_fold=i,
                    current_subject=person_num
                )
            
            fold_idx +=1
        
        # Ø¨Ø¹Ø¯ Ø§Ø² Ú©Ø§Ù…Ù„ Ø´Ø¯Ù† Ù‡Ù…Ù‡ foldÙ‡Ø§ÛŒ ÛŒÚ© subject
        train_acc  /=k
        train_loss /=k
        val_loss   /=k
        val_acc    /=k

        accuracies_on_subjects['train'].append(np.mean(np.array(train_acc[-5:])))
        accuracies_on_subjects['test'].append(np.mean(np.array(val_acc[-5:])))
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ config Ø¨Ø¹Ø¯ Ø§Ø² Ú©Ø§Ù…Ù„ Ø´Ø¯Ù† subject
        if config_path and run_dir:
            manager = ExperimentManager()
            manager.update_experiment_config(
                config_path,
                last_completed_subject=person_num,
                last_completed_fold=k-1,  # Ù‡Ù…Ù‡ foldÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡
                accuracies={
                    'train': accuracies_on_subjects['train'],
                    'test': accuracies_on_subjects['test']
                }
            )
            print(f"âœ… Subject {person_num} completed and saved to config")
        
        person_num +=1
    
    return accuracies_on_subjects













